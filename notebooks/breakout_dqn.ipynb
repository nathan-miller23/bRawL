{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import ray\n",
    "import gym\n",
    "from IPython import display\n",
    "import ray.rllib.agents.dqn as dqn\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "from ray.rllib.models.torch.torch_modelv2 import TorchModelV2\n",
    "from ray.rllib.utils.annotations import override\n",
    "from ray.rllib.utils.framework import try_import_torch\n",
    "\n",
    "torch, nn = try_import_torch()\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class ConvNet(TorchModelV2, nn.Module):\n",
    "    \"\"\"Generic fully connected network.\"\"\"\n",
    "\n",
    "    def __init__(self, obs_space, action_space, num_outputs, model_config,\n",
    "                 name):\n",
    "        TorchModelV2.__init__(self, obs_space, action_space, num_outputs,\n",
    "                              model_config, name)\n",
    "        nn.Module.__init__(self)\n",
    "        in_channels = obs_space.shape[-1]\n",
    "        self._conv_layers = nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels, 8, kernel_size=[7,7], padding=3),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(2, stride=2, padding=1),\n",
    "            torch.nn.Conv2d(8, 16, kernel_size=[5,5], padding=2),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(2, stride=2, padding=1),\n",
    "            torch.nn.Conv2d(16, 32, kernel_size=[3,3], padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(2, stride=2, padding=1),\n",
    "            torch.nn.Conv2d(32, num_outputs, kernel_size=[12,12])\n",
    "        )\n",
    "        self._features = None\n",
    "        self._num_outputs = num_outputs\n",
    "\n",
    "        \n",
    "\n",
    "    @override(TorchModelV2)\n",
    "    def forward(self, input_dict, state, seq_lens):\n",
    "        obs = input_dict[\"obs\"].float().permute(0,3,1,2) #reshape input\n",
    "        self._features = self._conv_layers(obs).view(-1, self._num_outputs)\n",
    "        return self._features, state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.tune.registry import register_env\n",
    "from ray.rllib.agents import dqn\n",
    "import numpy as np\n",
    "class MultiFrameBreakout(gym.Env):\n",
    "    def __init__(self, env_config):\n",
    "        self.env = gym.make('Breakout-v0')\n",
    "        self.action_space = self.env.action_space\n",
    "        self.observation_space = self.env.observation_space\n",
    "    def reset(self):\n",
    "        return self.env.reset()\n",
    "    def step(self, action):\n",
    "        return self.env.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-03 11:58:21,832\tWARNING util.py:39 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 4, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 32, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, '_time_major': False, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {}, 'env': None, 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.0005, 'monitor': False, 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'EpsilonGreedy', 'initial_epsilon': 1.0, 'final_epsilon': 0.02, 'epsilon_timesteps': 10000}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {'explore': False}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 1, 'timesteps_per_iteration': 1000, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': '/tmp/breakout_out', 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {}, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'logger_config': None, 'replay_sequence_length': 1, 'num_atoms': 1, 'v_min': -10.0, 'v_max': 10.0, 'noisy': False, 'sigma0': 0.5, 'dueling': True, 'hiddens': [256], 'double_q': True, 'n_step': 1, 'target_network_update_freq': 500, 'buffer_size': 50000, 'prioritized_replay': True, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'final_prioritized_replay_beta': 0.4, 'prioritized_replay_beta_annealing_timesteps': 20000, 'prioritized_replay_eps': 1e-06, 'before_learn_on_batch': None, 'training_intensity': None, 'lr_schedule': None, 'adam_epsilon': 1e-08, 'grad_clip': 40, 'learning_starts': 1000, 'worker_side_prioritization': False}\n",
      "0.5714285714285714\n",
      "checkpoint saved at /home/wangjim19/ray_results/DQN_BreakoutNoFrameskip-v4_2020-11-03_11-58-210b1hl2a_/checkpoint_1/checkpoint-1\n",
      "0.8461538461538461\n",
      "0.8947368421052632\n",
      "0.8846153846153846\n",
      "0.90625\n"
     ]
    }
   ],
   "source": [
    "#RLLIB DEFAULT\n",
    "\n",
    "from ray.rllib.agents import dqn\n",
    "\n",
    "config = dqn.DEFAULT_CONFIG.copy()\n",
    "config['framework'] = 'torch'\n",
    "config['output'] = '/tmp/breakout_out'\n",
    "trainer = dqn.DQNTrainer(env='BreakoutNoFrameskip-v4', config=config)\n",
    "policy = trainer.get_policy()\n",
    "model = policy.q_model\n",
    "env = trainer.workers.local_worker().env\n",
    "print(config)\n",
    "for i in range(5):\n",
    "    episode_reward_mean = trainer.train()['episode_reward_mean']\n",
    "    if i % 1 == 0:\n",
    "        print(episode_reward_mean)\n",
    "    if i % 20 == 0:\n",
    "        checkpoint = trainer.save()\n",
    "        print('checkpoint saved at', checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CUSTOM ENVIRONMENT\n",
    "\n",
    "register_env(\"multiframe\", lambda config: MultiFrameBreakout(config))\n",
    "config = dqn.DEFAULT_CONFIG.copy()\n",
    "config['framework'] = 'torch'\n",
    "config['num_gpus'] = 2\n",
    "trainer = dqn.DQNTrainer(env='multiframe', config=config)\n",
    "policy = trainer.get_policy()\n",
    "model = policy.q_model\n",
    "\n",
    "env = trainer.workers.local_worker().env\n",
    "print(env.observation_space)\n",
    "\"\"\"for i in range(100):\n",
    "    print(trainer.train()['episode_reward_mean'])\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNet_as_DQNTorchModel(\n",
      "  (_conv_layers): Sequential(\n",
      "    (0): Conv2d(4, 8, kernel_size=[7, 7], stride=(1, 1), padding=(3, 3))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(8, 16, kernel_size=[5, 5], stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(16, 32, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU()\n",
      "    (8): MaxPool2d(kernel_size=2, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (9): Conv2d(32, 256, kernel_size=[12, 12], stride=(1, 1))\n",
      "  )\n",
      "  (advantage_module): Sequential(\n",
      "    (dueling_A_0): SlimFC(\n",
      "      (_model): Sequential(\n",
      "        (0): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (1): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (dueling_A_1): SlimFC(\n",
      "      (_model): Sequential(\n",
      "        (0): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (1): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (A): SlimFC(\n",
      "      (_model): Sequential(\n",
      "        (0): Linear(in_features=256, out_features=4, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (value_module): Sequential(\n",
      "    (dueling_V_0): SlimFC(\n",
      "      (_model): Sequential(\n",
      "        (0): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (1): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (dueling_V_1): SlimFC(\n",
      "      (_model): Sequential(\n",
      "        (0): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (1): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (V): SlimFC(\n",
      "      (_model): Sequential(\n",
      "        (0): Linear(in_features=256, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "57.51\n",
      "checkpoint saved at /home/wangjim19/ray_results/DQN_BreakoutNoFrameskip-v4_2020-11-03_14-49-363v92_u8h/checkpoint_1201/checkpoint-1201\n",
      "57.51\n",
      "57.46\n",
      "54.39\n",
      "57.74\n",
      "57.74\n",
      "60.11\n",
      "63.15\n",
      "63.12\n",
      "63.72\n",
      "63.79\n",
      "63.17\n",
      "63.15\n",
      "63.29\n",
      "63.68\n",
      "63.45\n",
      "63.63\n",
      "63.77\n",
      "63.66\n",
      "63.27\n",
      "60.49\n",
      "checkpoint saved at /home/wangjim19/ray_results/DQN_BreakoutNoFrameskip-v4_2020-11-03_14-49-363v92_u8h/checkpoint_1221/checkpoint-1221\n",
      "60.83\n",
      "60.45\n",
      "60.72\n",
      "60.65\n",
      "60.61\n",
      "60.7\n",
      "60.35\n",
      "63.06\n",
      "63.46\n",
      "63.16\n",
      "62.96\n",
      "62.93\n",
      "63.3\n",
      "63.18\n",
      "63.27\n",
      "63.34\n",
      "62.16\n",
      "62.0\n",
      "61.84\n",
      "61.33\n",
      "checkpoint saved at /home/wangjim19/ray_results/DQN_BreakoutNoFrameskip-v4_2020-11-03_14-49-363v92_u8h/checkpoint_1241/checkpoint-1241\n",
      "61.06\n",
      "61.0\n",
      "60.93\n",
      "61.01\n",
      "60.41\n",
      "60.41\n",
      "61.11\n",
      "61.07\n",
      "60.73\n",
      "60.34\n",
      "60.16\n",
      "60.41\n",
      "60.52\n",
      "60.42\n",
      "62.09\n",
      "61.67\n",
      "61.45\n",
      "61.43\n",
      "61.49\n",
      "61.77\n",
      "checkpoint saved at /home/wangjim19/ray_results/DQN_BreakoutNoFrameskip-v4_2020-11-03_14-49-363v92_u8h/checkpoint_1261/checkpoint-1261\n",
      "61.76\n",
      "58.83\n",
      "56.83\n",
      "56.43\n",
      "56.44\n",
      "56.31\n",
      "56.47\n",
      "53.9\n",
      "53.79\n",
      "53.87\n",
      "52.9\n",
      "52.89\n",
      "52.74\n",
      "52.63\n",
      "52.54\n",
      "52.79\n",
      "52.86\n",
      "52.84\n",
      "54.72\n",
      "54.72\n",
      "checkpoint saved at /home/wangjim19/ray_results/DQN_BreakoutNoFrameskip-v4_2020-11-03_14-49-363v92_u8h/checkpoint_1281/checkpoint-1281\n",
      "54.84\n",
      "56.83\n",
      "56.83\n",
      "57.66\n",
      "57.14\n",
      "57.34\n",
      "57.05\n",
      "57.11\n",
      "57.16\n",
      "57.12\n",
      "60.13\n",
      "57.29\n",
      "54.85\n",
      "51.19\n",
      "51.54\n",
      "51.06\n",
      "51.09\n",
      "51.46\n",
      "51.46\n",
      "51.78\n",
      "checkpoint saved at /home/wangjim19/ray_results/DQN_BreakoutNoFrameskip-v4_2020-11-03_14-49-363v92_u8h/checkpoint_1301/checkpoint-1301\n",
      "51.92\n",
      "51.83\n",
      "51.96\n",
      "52.2\n",
      "52.07\n",
      "51.62\n",
      "51.59\n",
      "52.02\n",
      "52.23\n",
      "52.53\n",
      "54.11\n",
      "53.91\n",
      "53.9\n",
      "53.68\n",
      "53.66\n",
      "55.47\n",
      "55.63\n",
      "53.11\n",
      "55.85\n",
      "55.88\n",
      "checkpoint saved at /home/wangjim19/ray_results/DQN_BreakoutNoFrameskip-v4_2020-11-03_14-49-363v92_u8h/checkpoint_1321/checkpoint-1321\n",
      "55.97\n",
      "55.97\n",
      "56.03\n",
      "55.84\n",
      "55.98\n",
      "55.55\n",
      "55.75\n",
      "57.4\n",
      "57.41\n",
      "59.77\n",
      "62.61\n",
      "59.86\n",
      "60.13\n"
     ]
    }
   ],
   "source": [
    "#CUSTOM MODEL\n",
    "\n",
    "\"\"\"from ray.rllib.models import ModelCatalog\n",
    "\n",
    "ray.shutdown()\n",
    "\n",
    "ModelCatalog.register_custom_model(\"ConvNet\", ConvNet)\n",
    "\n",
    "ray.init()\n",
    "trainer = dqn.DQNTrainer(env=\"BreakoutNoFrameskip-v4\", config={\n",
    "    \"framework\": \"torch\",\n",
    "    \"hiddens\": [256,256],\n",
    "    \"num_gpus\": 2,\n",
    "    \"preprocessor_pref\": \"deepmind\",\n",
    "    \"model\": {\n",
    "        \"custom_model\": \"ConvNet\",\n",
    "        # Extra kwargs to be passed to your model's c'tor.\n",
    "        \"custom_model_config\": {},\n",
    "        \"use_lstm\": False,\n",
    "        \"framestack\": True\n",
    "    },\n",
    "    \"lr\": 1e-5,\n",
    "    \"exploration_config\": {\n",
    "        \"epsilon_timesteps\": 100000,\n",
    "    },\n",
    "    \"output\": \"/tmp/breakout_out1\",\n",
    "    \"monitor\": True\n",
    "})\"\"\"\n",
    "\n",
    "\n",
    "policy = trainer.get_policy()\n",
    "model = policy.q_model\n",
    "print(model)\n",
    "for i in range(600):\n",
    "    episode_reward_mean = trainer.train()['episode_reward_mean']\n",
    "    if i % 1 == 0:\n",
    "        print(episode_reward_mean)\n",
    "    if i % 20 == 0:\n",
    "        checkpoint = trainer.save()\n",
    "        print('checkpoint saved at', checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CUSTOM MODEL AND CUSTOM ENVIRONMENT\n",
    "\n",
    "from ray.rllib.models import ModelCatalog\n",
    "\n",
    "ray.shutdown()\n",
    "\n",
    "ModelCatalog.register_custom_model(\"ConvNet\", ConvNet)\n",
    "\n",
    "ray.init()\n",
    "trainer = dqn.DQNTrainer(env=MultiFrameBreakout, config={\n",
    "    \"framework\": \"torch\",\n",
    "    \"hiddens\": [256,256],\n",
    "    \"num_gpus\": 2,\n",
    "    \"preprocessor_pref\": \"deepmind\",\n",
    "    \"model\": {\n",
    "        \"custom_model\": \"ConvNet\",\n",
    "        # Extra kwargs to be passed to your model's c'tor.\n",
    "        \"custom_model_config\": {},\n",
    "        \"use_lstm\": True\n",
    "    },\n",
    "})\n",
    "\n",
    "\n",
    "policy = trainer.get_policy()\n",
    "model = policy.q_model\n",
    "print(model)\n",
    "\n",
    "env = trainer.workers.local_worker().env\n",
    "print(env.observation_space)\n",
    "for i in range(100):\n",
    "    episode_reward_mean = trainer.train()['episode_reward_mean']\n",
    "    if i % 1 == 0:\n",
    "        print(episode_reward_mean)\n",
    "    if i % 100 == 0:\n",
    "        checkpoint = trainer.save()\n",
    "        print('checkpoint saved at', checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"env = copy.deepcopy(trainer.workers.local_worker().env)\\nfor i in range(10):\\n    episode_reward = 0\\n    done = False\\n    obs = env.reset()\\n    \\n    while not done:\\n        action = trainer.compute_action(obs)\\n        obs, reward, done, info = env.step(action)\\n        episode_reward += reward\\n        plt.imshow(env.render(mode='rgb_array'))\\n        display.display(plt.gcf())\\n        display.clear_output(wait=True)\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython import display\n",
    "import copy\n",
    "\n",
    "\n",
    "env = trainer.workers.local_worker().env\n",
    "plt.imshow(env.render(mode='rgb_array'))\n",
    "display.display(plt.gcf())\n",
    "display.clear_output(wait=True)\n",
    "\"\"\"obs, reward, done, info = env.step(env.action_space.sample())\n",
    "for i in range(10):\n",
    "    while not done:\n",
    "        action = trainer.compute_action(obs)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        plt.imshow(env.render(mode='rgb_array'))\n",
    "        display.display(plt.gcf())\n",
    "        display.clear_output(wait=True)\"\"\"\n",
    "\"\"\"env = copy.deepcopy(trainer.workers.local_worker().env)\n",
    "for i in range(10):\n",
    "    episode_reward = 0\n",
    "    done = False\n",
    "    obs = env.reset()\n",
    "    \n",
    "    while not done:\n",
    "        action = trainer.compute_action(obs)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        episode_reward += reward\n",
    "        plt.imshow(env.render(mode='rgb_array'))\n",
    "        display.display(plt.gcf())\n",
    "        display.clear_output(wait=True)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-03 12:30:51,806\tWARNING util.py:39 -- Install gputil for GPU system monitoring.\n",
      "2020-11-03 12:30:51,856\tINFO trainable.py:482 -- Restored on 128.32.112.46 from checkpoint: /home/wangjim19/ray_results/DQN_BreakoutNoFrameskip-v4_2020-11-01_17-52-565elpxf2c/checkpoint_301/checkpoint-301\n",
      "2020-11-03 12:30:51,857\tINFO trainable.py:489 -- Current state after restoring: {'_iteration': 301, '_timesteps_total': None, '_time_total': 4230.372759342194, '_episodes_total': 662}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1666666666666667\n"
     ]
    }
   ],
   "source": [
    "trainer = dqn.DQNTrainer(env=\"BreakoutNoFrameskip-v4\", config={\n",
    "    \"framework\": \"torch\",\n",
    "    \"hiddens\": [256,256],\n",
    "    \"num_gpus\": 2,\n",
    "    \"preprocessor_pref\": \"deepmind\",\n",
    "    \"model\": {\n",
    "        \"custom_model\": \"ConvNet\",\n",
    "        # Extra kwargs to be passed to your model's c'tor.\n",
    "        \"custom_model_config\": {},\n",
    "        \"use_lstm\": False,\n",
    "        \"framestack\": True\n",
    "    },\n",
    "    \"lr\": 1e-5,\n",
    "    \"exploration_config\": {\n",
    "        \"epsilon_timesteps\": 100000,\n",
    "    },\n",
    "})\n",
    "trainer.restore('/home/wangjim19/ray_results/DQN_BreakoutNoFrameskip-v4_2020-11-01_17-52-565elpxf2c/checkpoint_301/checkpoint-301')\n",
    "print(trainer.train()['episode_reward_mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2571428571428571\n"
     ]
    }
   ],
   "source": [
    "trainer.config['output'] = '/tmp/breakout_out'\n",
    "print(trainer.train()['episode_reward_mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
