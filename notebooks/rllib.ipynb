{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bRawL Project Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will walk you through some of the gym, rllib and sacred basics. These are all tools we will be using throughout this project, so it's best to get a solid working familiarity with them from the getgo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Begin with some imports\n",
    "import torch\n",
    "import ray\n",
    "import gym\n",
    "from IPython import display\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's verify that torch can see our GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Should return `True`\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The central mathematical object that underpins all reinforcement learning is the Markov Decision Process (MDP). As you learned, the MDP can be represented as a four tuple $(\\mathcal{S}, \\mathcal{A}, \\mathcal{T}, R)$, where $\\mathcal{S}$ is the state space, $\\mathcal{A}$ is the action space, $\\mathcal{T} : \\mathcal{S} x \\mathcal{A} \\longrightarrow \\mathcal{S}$ is the transition function that encodes the state dynamics, and $\\mathcal{R} : \\mathcal{S} x \\mathcal{A} \\longrightarrow \\mathbb{R}$ is the reward function\n",
    "\n",
    "In practice, we represent such an object using an environment class, usually one that follows the [gym](https://gym.openai.com/) API. The `Environment` class has the following core functions that all subclasses must implement:\n",
    "\n",
    "`step(action)`:  \n",
    "\n",
    "Takes in an action and returns a tuple `(observation, reward, done, info)` where `observation` is the new state we arrive at, `reward` is a scalar represeting how much reward the agent got at this timestep, `done` is a boolean indicating whether the current episode has terminated, and `info` is reserved for whatever metadata  \n",
    "\n",
    "`reset()`:  \n",
    "\n",
    "Called at the beginning of every episode, used to instantiate all agents and environment artifacts, returns initial state observation. \n",
    "\n",
    "In addition, the `Environment` class has `observation_space` and `action_space` members that represent the set of allowable states and actions. Environments can be created by calling `gym.make('<environment_name>')`\n",
    "\n",
    "\n",
    "\n",
    "Let's look at a specific example below, the classic Atari game, Breakout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation space Box(0, 255, (210, 160, 3), uint8)\n",
      "Action space Discrete(4)\n",
      "Initial state shape (210, 160, 3)\n"
     ]
    }
   ],
   "source": [
    "breakout_env = gym.make('Breakout-v0')\n",
    "\n",
    "ob_space = breakout_env.observation_space\n",
    "ac_space = breakout_env.action_space\n",
    "\n",
    "initial_state = breakout_env.reset()\n",
    "\n",
    "print(\"Observation space\", ob_space)\n",
    "print(\"Action space\", ac_space)\n",
    "print(\"Initial state shape\", initial_state.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if we can visualize a state of the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Render shape (210, 160, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd118c4b6d8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = breakout_env.render(mode='rgb_array')\n",
    "print(\"Render shape\", img.shape)\n",
    "plt.imshow(breakout_env.render(mode='rgb_array'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the `observation` array is precisely a RGB image representing the pixels on the game\n",
    "\n",
    "Now let's visualize a rollout generated by randomly sampling actions at every timestep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "breakout_env.reset()\n",
    "for _ in range(100):\n",
    "    plt.imshow(breakout_env.render(mode='rgb_array'))\n",
    "    display.display(plt.gcf())\n",
    "    display.clear_output(wait=True)\n",
    "    action = breakout_env.action_space.sample()\n",
    "    breakout_env.step(action)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oof. That was... not great....\n",
    "\n",
    "But do not despair, this is where the RL comes in. Our agents will learn to behave intelligently by the end of this if all goes according to plan. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rllib "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Policies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's get a sense of some of the inner workings of Rllib, the library we'll be using to train our agents. The key abstraction in rllib is the `Policy` object. The policy represents a function that accepts an input state, and outputs a distribution over possible actions the agent should take at this state. \n",
    "\n",
    "The policy class takes in an `observation_space` and `action_space` as parameters, and implements the function `compute_actions`, `learn_on_batch` and `compute_log_likelihoods`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a sense of how policies work, let's see if we can implement our random policy from above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From //anaconda3/lib/python3.7/site-packages/tensorflow/python/compat/v2_compat.py:61: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "from ray.rllib.policy.policy import Policy\n",
    "\n",
    "class RandomPolicy(Policy):\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "        # TODO: Set some instance variables here\n",
    "        # Note: the super constructor will set the instance variables `action_space` and `observation_space` for you\n",
    "        pass\n",
    "    \n",
    "    def compute_actions(self,\n",
    "                        obs_batch,\n",
    "                        state_batches=None,\n",
    "                        prev_action_batch=None,\n",
    "                        prev_reward_batch=None,\n",
    "                        **kwargs):\n",
    "        # Randomly sample an action\n",
    "        pass\n",
    "    \n",
    "    def learn_on_batch(self, samples):\n",
    "        \"\"\"No learning.\"\"\"\n",
    "        return {}\n",
    "    \n",
    "    def compute_log_likelihoods(self,\n",
    "                                actions,\n",
    "                                obs_batch,\n",
    "                                state_batches=None,\n",
    "                                prev_action_batch=None,\n",
    "                                prev_reward_batch=None):\n",
    "        # Return logits from a uniform distribution\n",
    "        pass\n",
    "    def get_weights(self):\n",
    "        \"\"\"\n",
    "        No-op to keep rllib from breaking, won't be necessary in future rllib releases\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def set_weights(self, weights):\n",
    "        \"\"\"\n",
    "        No-op to keep rllib from breaking\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.rllib.env.multi_agent_env import MultiAgentEnv\n",
    "class BreakoutRllib(MultiAgentEnv):\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self._env = gym.make('Breakout-v0')\n",
    "        self.action_space = self._env.action_space\n",
    "        self.observation_space = self._env.observation_space\n",
    "        \n",
    "        \n",
    "    def step(self, action):\n",
    "        obs, reward, done, info = self._env.step(action)\n",
    "        return { \"random\" : obs }, reward, done, info\n",
    "    \n",
    "    def reset(self):\n",
    "        return self._env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-27 20:24:31,322\tINFO resource_spec.py:231 -- Starting Ray with 1.51 GiB memory available for workers and up to 0.78 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2020-09-27 20:24:31,769\tINFO services.py:1193 -- View the Ray dashboard at \u001b[1m\u001b[32mlocalhost:8265\u001b[39m\u001b[22m\n",
      "2020-09-27 20:24:31,775\tWARNING services.py:1567 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 67084288 bytes available. This may slow down performance! You may be able to free up space by deleting files in /dev/shm or terminating any running plasma_store_server processes. If you are inside a Docker container, you may need to pass an argument with the flag '--shm-size' to 'docker run'.\n",
      "2020-09-27 20:24:31,794\tWARNING services.py:1567 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 67084288 bytes available. This may slow down performance! You may be able to free up space by deleting files in /dev/shm or terminating any running plasma_store_server processes. If you are inside a Docker container, you may need to pass an argument with the flag '--shm-size' to 'docker run'.\n",
      "2020-09-27 20:24:33,014\tWARNING worker.py:1134 -- The dashboard on node b13c8ff69a98 failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 1073, in create_server\n",
      "    sock.bind(sa)\n",
      "OSError: [Errno 99] Cannot assign requested address\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/env/lib/python3.6/site-packages/ray/dashboard/dashboard.py\", line 961, in <module>\n",
      "    dashboard.run()\n",
      "  File \"/env/lib/python3.6/site-packages/ray/dashboard/dashboard.py\", line 576, in run\n",
      "    aiohttp.web.run_app(self.app, host=self.host, port=self.port)\n",
      "  File \"/env/lib/python3.6/site-packages/aiohttp/web.py\", line 433, in run_app\n",
      "    reuse_port=reuse_port))\n",
      "  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 488, in run_until_complete\n",
      "    return future.result()\n",
      "  File \"/env/lib/python3.6/site-packages/aiohttp/web.py\", line 359, in _run_app\n",
      "    await site.start()\n",
      "  File \"/env/lib/python3.6/site-packages/aiohttp/web_runner.py\", line 104, in start\n",
      "    reuse_port=self._reuse_port)\n",
      "  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 1077, in create_server\n",
      "    % (sa, err.strerror.lower()))\n",
      "OSError: [Errno 99] error while attempting to bind on address ('::1', 8265, 0, 0): cannot assign requested address\n",
      "\n",
      "2020-09-27 20:24:33,090\tWARNING util.py:37 -- Install gputil for GPU system monitoring.\n"
     ]
    }
   ],
   "source": [
    "# Some ray setup\n",
    "from ray.rllib.agents.ppo.ppo import PPOTrainer\n",
    "from ray.tune.registry import register_env\n",
    "ray.init()\n",
    "\n",
    "# Register the gym environment (Note that this is different than the gym registry!)\n",
    "register_env(\"breakout\",\n",
    "             lambda _: BreakoutRllib())\n",
    "obs_space = breakout_env.observation_space\n",
    "act_space = breakout_env.action_space\n",
    "\n",
    "config = config={\n",
    "        \"multiagent\": {\n",
    "            \"policies\": {\n",
    "                \"random\": (RandomPolicy, obs_space, act_space, {}),\n",
    "            },\n",
    "            \"policy_mapping_fn\": (\n",
    "                lambda agent_id: \"random\"),\n",
    "        },\n",
    "        \"num_workers\" : 1,\n",
    "        \"framework\": \"torch\"\n",
    "}\n",
    "\n",
    "trainer = PPOTrainer(env=\"breakout\", config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sacred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another useful tool we will be using is sacred. It offers us two conviences: syntatic sugar for command line calls, as well as automated slack notifications for when trainings complete. The api is simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an experiment object\n",
    "from sacred import Experiment\n",
    "ex = Experiment(\"My Experiment\", interactive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ex.config\n",
    "def my_config():\n",
    "    # Define any parameters and its defaults here\n",
    "    \n",
    "    a = 1\n",
    "    b = 2\n",
    "    c = 3\n",
    "    \n",
    "    params = {\n",
    "        \"a\" : a,\n",
    "        \"b\" : b,\n",
    "        \"c\" : c\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ex.main\n",
    "def main(params):\n",
    "    for (key, value) in params.items():\n",
    "        print(\"Parameter {} is set to {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - My Experiment - No observers have been added to this run\n",
      "INFO - My Experiment - Running command 'main'\n",
      "INFO - My Experiment - Started\n",
      "INFO - My Experiment - Completed after 0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter a is set to 1\n",
      "Parameter b is set to 2\n",
      "Parameter c is set to 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sacred.run.Run at 0x7f22801b0d68>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the `params` defined in `my_config` was passed into `main` when we ran the experiment. We can override defualt values in python using the following syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - root - Changed type of config entry \"c\" from int to str\n",
      "WARNING - My Experiment - No observers have been added to this run\n",
      "INFO - My Experiment - Running command 'main'\n",
      "INFO - My Experiment - Started\n",
      "INFO - My Experiment - Completed after 0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter a is set to 1\n",
      "Parameter b is set to 2\n",
      "Parameter c is set to this is a non-default setting!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sacred.run.Run at 0x7f228049d908>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex.run(config_updates={'c' : 'this is a non-default setting!'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the value of `c` was updated, and sacred even gave us a type warning, a true luxury in the python world!\n",
    "\n",
    "If saved all the above code in a file called `foo.py` we could run the experiment from the command line by executing \n",
    "```\n",
    "python foo.py \n",
    "```\n",
    "\n",
    "In order to update `c` as we did in the second run, we would execute\n",
    "```\n",
    "python foo.py with c=\"this is a non-default setting!\"\n",
    "```\n",
    "\n",
    "The general syntax for upating any param is\n",
    "```\n",
    "python foo.py with <param_1>=<val_1> <param_2>=<val_2>...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
